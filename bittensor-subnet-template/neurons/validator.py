import os
import time
import torch
import argparse
import traceback
import bittensor as bt
import template
import openai
import os
import wandb
import json
from collections import OrderedDict

wandb.init(project="openai_qa", name="run1")

# Do this for the openai api key in terminal: echo "export OPENAI_API_KEY=your_api_key_here">>~/.bashrc && source ~/.bashrc
openai.api_key = os.environ.get('OPENAI_API_KEY')
if not openai.api_key:
    raise ValueError("Please set the OPENAI_API_KEY environment variable.")

def get_config():
    parser = argparse.ArgumentParser()
    parser.add_argument("--alpha", default=0.9, type=float)
    parser.add_argument("--custom", default="my_custom_value")
    parser.add_argument("--netuid", type=int, default=1)
    bt.subtensor.add_args(parser)
    bt.logging.add_args(parser)
    bt.wallet.add_args(parser)
    config = bt.config(parser)
    config.full_path = os.path.expanduser(f"{config.logging.logging_dir}/{config.wallet.name}/{config.wallet.hotkey}/netuid{config.netuid}/validator")
    if not os.path.exists(config.full_path):
        os.makedirs(config.full_path, exist_ok=True)
    return config
def initialize_components(config):
    bt.logging(config=config, logging_dir=config.full_path)
    bt.logging.info(f"Running validator for subnet: {config.netuid} on network: {config.subtensor.chain_endpoint}")
    wallet = bt.wallet(config=config)
    subtensor = bt.subtensor(config=config)
    dendrite = bt.dendrite(wallet=wallet)
    metagraph = subtensor.metagraph(config.netuid)
    return wallet, subtensor, dendrite, metagraph

def check_validator_registration(wallet, subtensor, metagraph):
    if wallet.hotkey.ss58_address not in metagraph.hotkeys:
        bt.logging.error(f"Your validator: {wallet} is not registered to chain connection: {subtensor}. Run btcli register and try again.")
        exit()

def get_openai_answer(query, engine):
    try:
        messages = [{"role": "user", "content": query}]
        response = openai.ChatCompletion.create(
            model=engine,
            messages=messages,
            temperature=0,
        )
        answer = response["choices"][0]["message"]["content"].strip()
        bt.logging.info(f"Response from openai: {answer}")
        return answer
    except Exception as e:
        bt.logging.info(f"Error when calling OpenAI: {e}")
        return None


def set_weights(step, scores, config, subtensor, wallet, metagraph):
    weights = torch.nn.functional.normalize(scores, p=1.0, dim=0)
    bt.logging.info(f"weights is {weights}")

    result = subtensor.set_weights(netuid=config.netuid, wallet=wallet, uids=metagraph.uids, weights=weights, wait_for_inclusion=True)
    if result:
        bt.logging.success("Successfully set weights.")
    else:
        bt.logging.error("Failed to set weights.")

def log_wandb(query, engine, responses_dict, step, timestamp):
    # Organize general data fields at the beginning
    data = {
        '_timestamp': timestamp,
        '_runtime': time.time() - timestamp,
        'engine': engine,
        'prompt': query,
        '_step': step,
        'responses': []  # Initialize responses list
    }

    # Organize response data in a consistent order
    for uid, response_data in responses_dict.items():
        response_entry = {
            'uid': uid,
            'response': response_data.get('response', None),
            'score': response_data.get('score', 0)
        }
        data['responses'].append(response_entry)

    wandb.log(data)

def score_responses(openai_answer, responses, config, scores):
    responses_dict = {}
    for i, resp_i in enumerate(responses):
        score = template.reward.openai_score(openai_answer, resp_i)
        bt.logging.info(f"Received response: {resp_i} from miner with UID {i}. Assigned score: {score}")
        # Organize response data in a consistent order
        responses_dict[i] = {
            'response': resp_i,
            'score': score
        }
        scores[i] = config.alpha * scores[i] + (1 - config.alpha) * score
    
    bt.logging.info(f"scores = {scores}")
    return responses_dict


def run_validator_loop(wallet, subtensor, dendrite, metagraph, config, scores):
    step = 0
    while True:
        try:
            query = "briefly describe the moon"
            engine = "gpt-3.5-turbo"
            responses = dendrite.query(metagraph.axons, template.protocol.Openai(openai_input=query, openai_engine=engine), deserialize=True)
            bt.logging.info(f"Sent query to miner: '{query}' using {engine}")

            openai_answer = get_openai_answer(query, engine)
            if openai_answer:
                responses_dict = score_responses(openai_answer, responses, config, scores)
                bt.logging.info(f"responses_dict is {responses_dict}")
                log_wandb(query, engine, responses_dict, step, time.time())

            if (step + 1) % 25 == 0:  
                set_weights(step, scores, config, subtensor, wallet, metagraph)

            bt.logging.info(f"step = {step}")
            step += 1
            metagraph = subtensor.metagraph(config.netuid)
            time.sleep(bt.__blocktime__)

        except RuntimeError as e:
            bt.logging.error(e)
        except KeyboardInterrupt:
            bt.logging.success("Keyboard interrupt detected. Exiting validator.")
            exit()


def main(config):
    wallet, subtensor, dendrite, metagraph = initialize_components(config)
    check_validator_registration(wallet, subtensor, metagraph)
    my_subnet_uid = metagraph.hotkeys.index(wallet.hotkey.ss58_address)
    scores = torch.ones_like(metagraph.S, dtype=torch.float32)

    run_validator_loop(wallet, subtensor, dendrite, metagraph, config, scores)

if __name__ == "__main__":
    main(get_config())
